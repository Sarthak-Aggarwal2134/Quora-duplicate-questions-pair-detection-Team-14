{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIFEb8x-xjxQ"
      },
      "source": [
        "# Linear Models - Logistic Regression and SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UBImvzdxLGa"
      },
      "source": [
        "Importing the necesssary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MCWYp7cYzQyr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as numpy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXTHg-bXxJQM"
      },
      "source": [
        "Importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O7wy8XgE_VlE"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "data = data.dropna(how=\"any\").reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkP6tWnX_EGt"
      },
      "source": [
        "### LR with Unigrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf0aD7rGxSwz"
      },
      "source": [
        "Obtaining unigram counts using CountVectorizer. Skipping preprocessing (tokenization and removal of ASCII characters) as CountVectorizer does it internally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yQAFREVEphmV"
      },
      "outputs": [],
      "source": [
        "cnt = CountVectorizer(analyzer='word', ngram_range=(1,1), lowercase=True)\n",
        "cnt.fit(pd.concat((data['question1'],data['question2'])))\n",
        "q1 = data['question1']\n",
        "q2 = data['question2']\n",
        "q1 = cnt.transform(q1)\n",
        "q2 = cnt.transform(q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "87QjBEKBw7PW"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "xx = scipy.sparse.hstack((q1,q2))\n",
        "yy = data['is_duplicate']\n",
        "x_train_u, x_test_u, y_train_u, y_test_u = train_test_split(xx, yy,  test_size=0.30, random_state=25)\n",
        "x_val_u, x_test_u, y_val_u, y_test_u = train_test_split(x_test_u, y_test_u ,test_size=float(1/3), random_state=25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL3MFjz_8-hr",
        "outputId": "b974a4b9-bc65-4c40-aa7f-9a39e00a8823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7489673254347127\n",
            "0.6449412258606214\n"
          ]
        }
      ],
      "source": [
        "uni = SGDClassifier(penalty='l2',alpha=0.00001, n_iter_no_change=20)\n",
        "uni.fit(x_train_u,y_train_u)\n",
        "y_pred = uni.predict(x_val_u)\n",
        "acc = accuracy_score(y_val_u, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_val_u,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7D2yFZbsmK0",
        "outputId": "6d849a45-c99c-44e2-c6dc-59bd68cbef86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7473843033466077\n",
            "0.633430242991996\n"
          ]
        }
      ],
      "source": [
        "uni = SGDClassifier(penalty='l2',alpha=0.00001, n_iter_no_change=20)\n",
        "uni.fit(x_train_u,y_train_u)\n",
        "y_pred = uni.predict(x_test_u)\n",
        "acc = accuracy_score(y_test_u, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_test_u,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhaiFeLr-94a"
      },
      "source": [
        "### LR with Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IIEeihlX_Ite"
      },
      "outputs": [],
      "source": [
        "data2 = pd.read_csv('./train.csv')\n",
        "data2 = data2.dropna(how=\"any\").reset_index(drop=True)\n",
        "cnt = CountVectorizer(analyzer='word', ngram_range=(1,2), lowercase=True)\n",
        "cnt.fit(pd.concat((data2['question1'],data2['question2'])))\n",
        "q1 = data2['question1']\n",
        "q2 = data2['question2']\n",
        "q1 = cnt.transform(q1)\n",
        "q2 = cnt.transform(q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ySeOsODw_X_a"
      },
      "outputs": [],
      "source": [
        "xx = scipy.sparse.hstack((q1,q2))\n",
        "yy = data2['is_duplicate']\n",
        "x_train_b, x_test_b, y_train_b, y_test_b = train_test_split(xx, yy,  test_size=0.30, random_state=25)\n",
        "x_val_b, x_test_b, y_val_b, y_test_b = train_test_split(x_test_b, y_test_b ,test_size=float(1/3), random_state=25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_UKAPrGtFFx",
        "outputId": "04c0cafc-58a9-497e-b8dd-ab6465833844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7803185831952312\n",
            "0.7010652799515323\n"
          ]
        }
      ],
      "source": [
        "bi = SGDClassifier(penalty='l2',alpha=0.00001, n_iter_no_change=20)\n",
        "bi.fit(x_train_b,y_train_b)\n",
        "y_pred = bi.predict(x_val_b)\n",
        "acc = accuracy_score(y_val_b, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_val_b,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVBEk6KI_cvv",
        "outputId": "2562cf96-c0a2-41c1-d3f6-367d55faf94b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7767196814168048\n",
            "0.7007260551006199\n"
          ]
        }
      ],
      "source": [
        "bi = SGDClassifier(penalty='l2',alpha=0.00001, n_iter_no_change=20)\n",
        "bi.fit(x_train_b,y_train_b)\n",
        "y_pred = bi.predict(x_test_b)\n",
        "acc = accuracy_score(y_test_b, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_test_b,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9ZJHIrn_uWd"
      },
      "source": [
        "### LR with Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vfGt1qJI_37Q"
      },
      "outputs": [],
      "source": [
        "data3 = pd.read_csv('./train.csv')\n",
        "data3 = data2.dropna(how=\"any\").reset_index(drop=True)\n",
        "cnt = CountVectorizer(analyzer='word', ngram_range=(1,3), lowercase=True)\n",
        "cnt.fit(pd.concat((data3['question1'],data3['question2'])))\n",
        "q1 = data3['question1']\n",
        "q2 = data3['question2']\n",
        "q1 = cnt.transform(q1)\n",
        "q2 = cnt.transform(q2)\n",
        "xx = scipy.sparse.hstack((q1,q2))\n",
        "yy = data3['is_duplicate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ahx87OoCCYjA"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train_t, x_test_t, y_train_t, y_test_t = train_test_split(xx, yy,  test_size=0.30, random_state=25)\n",
        "x_val_t, x_test_t, y_val_t, y_test_t = train_test_split(x_test_t, y_test_t ,test_size=float(1/3), random_state=25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnCVPUl5Ccgu",
        "outputId": "d58d034d-45f5-4241-e0ef-4e4b2df3b91e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7966806005590047\n",
            "0.7177197802197802\n"
          ]
        }
      ],
      "source": [
        "tri = SGDClassifier(penalty='l2',alpha=0.00001, n_iter_no_change=20)\n",
        "tri.fit(x_train_t,y_train_t)\n",
        "y_pred = tri.predict(x_test_t)\n",
        "acc = accuracy_score(y_test_t, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_test_t,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0mdWROLuIoD",
        "outputId": "54bea539-668a-4810-873d-9eb74ec9fb17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8020480348264859\n",
            "0.7016700216208156\n"
          ]
        }
      ],
      "source": [
        "tri = SGDClassifier(penalty='l2',alpha=0.0001, n_iter_no_change=20)\n",
        "tri.fit(x_train_t,y_train_t)\n",
        "y_pred = tri.predict(x_val_t)\n",
        "acc = accuracy_score(y_val_t, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_val_t,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCLhUs7Jwu9n"
      },
      "source": [
        "α = 0.0001 gives an accuracy of 80.13% and F score = 70.32. Highest F-score = 71.32 for α = 0.00001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glbWr6fxuk0v",
        "outputId": "e310bf19-3bf4-41c4-8700-b85cfca80324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.802320116747879\n",
            "0.7025568499013733\n"
          ]
        }
      ],
      "source": [
        "tri = SGDClassifier(penalty='l2',alpha=0.0001, n_iter_no_change=50)\n",
        "tri.fit(x_train_t,y_train_t)\n",
        "y_pred = tri.predict(x_val_t)\n",
        "acc = accuracy_score(y_val_t, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_val_t,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8S_YGU6zqQT"
      },
      "source": [
        "Most accuracy for n = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewww51K8DHnp"
      },
      "source": [
        "### LR with Trigrams, tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yWZrQUuDPc0",
        "outputId": "9f79ffe1-26e4-49d2-99bb-db003665e7ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8018006876252195\n",
            "0.7011970019017788\n"
          ]
        }
      ],
      "source": [
        "tri_t = SGDClassifier(penalty='l2',alpha=0.0001, n_iter_no_change=15)\n",
        "tri_t.fit(x_train_t,y_train_t)\n",
        "y_pred = tri_t.predict(x_test_t)\n",
        "acc = accuracy_score(y_test_t, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_test_t,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGvRA9EfKlKt"
      },
      "source": [
        "## SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2umzHbl18NBe",
        "outputId": "9bb81ed1-b1e3-4251-dc3c-3e3bae4b5e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7491157337554726\n",
            "0.5994234034990719\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "x_test_u1 = normalize(x_test_u, norm='l1', axis=1)\n",
        "x_train_u1 = normalize(x_train_u, norm='l1', axis=1)\n",
        "\n",
        "uni = LinearSVC(C=1)\n",
        "uni.fit(x_train_u1,y_train_u)\n",
        "y_pred = uni.predict(x_test_u1)\n",
        "acc = accuracy_score(y_test_u, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_test_u,y_pred)\n",
        "print(f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arBirp9Jbo1D"
      },
      "source": [
        "### Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2LCp0vLNmpv",
        "outputId": "d22a825d-1abb-45a2-8328-c5b7f42f573b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7562145984318187\n",
            "0.6493150684931507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tarun/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x_val_u1 = normalize(x_val_u, norm='l1', axis=1) #normalisation\n",
        "x_train_u1 = normalize(x_train_u, norm='l1', axis=1)\n",
        "\n",
        "uni = LinearSVC(C=50, max_iter=1000)\n",
        "uni.fit(x_train_u1,y_train_u)\n",
        "y_pred = uni.predict(x_val_u1)\n",
        "acc = accuracy_score(y_val_u, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_val_u,y_pred)\n",
        "print(f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whQbfGpNaGQp"
      },
      "source": [
        "### Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_HNolcY87jY",
        "outputId": "ab7545f3-ec02-42ca-ff6a-6da1460c0ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7577481510796705\n",
            "0.6045704134366924\n"
          ]
        }
      ],
      "source": [
        "x_test_b1 = normalize(x_test_b, norm='l1', axis=1)\n",
        "x_train_b1 = normalize(x_train_b, norm='l1', axis=1)\n",
        "\n",
        "uni = LinearSVC(C=1, max_iter=1000)\n",
        "uni.fit(x_train_b1,y_train_b)\n",
        "y_pred = uni.predict(x_test_b1)\n",
        "acc = accuracy_score(y_test_b, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_test_b,y_pred)\n",
        "print(f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgM3sgbSaPmr",
        "outputId": "59f14f7b-2ce2-4118-99ce-8d2c093728b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7989809295307824\n",
            "0.7078510317060895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tarun/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "x_val_b1 = normalize(x_val_b, norm='l1', axis=1)\n",
        "x_train_b1 = normalize(x_train_b, norm='l1', axis=1)\n",
        "\n",
        "bi = LinearSVC(C=50)\n",
        "bi.fit(x_train_b1,y_train_b)\n",
        "y_pred = bi.predict(x_val_b1)\n",
        "acc = accuracy_score(y_val_b, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_val_b,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7vEP6DYbKPk"
      },
      "source": [
        "### Trigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ9ONZ0PAKzQ"
      },
      "source": [
        "Hyperparameter tuning on the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khSTvGC3mNeX",
        "outputId": "86422444-f9ff-4e48-cc9d-691fd98cff36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8092829404635287\n",
            "0.7170925902144601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tarun/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x_val_t1 = normalize(x_val_t, norm='l1', axis=1)\n",
        "x_train_t1 = normalize(x_train_t, norm='l1', axis=1)\n",
        "\n",
        "tri = LinearSVC(C=50)\n",
        "tri.fit(x_train_t1,y_train_t)\n",
        "y_pred = tri.predict(x_val_t1)\n",
        "acc = accuracy_score(y_val_t, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_val_t,y_pred)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COfVI0OQASsH"
      },
      "source": [
        "Test set with tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaM3N_w6bcXH",
        "outputId": "aff92768-b4b0-4951-9a8d-68949015e918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8109772687922037\n",
            "0.7189614592527215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tarun/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "x_test_t1 = normalize(x_test_t, norm='l1', axis=1)\n",
        "x_train_t1 = normalize(x_train_t, norm='l1', axis=1)\n",
        "\n",
        "tri = LinearSVC(C=50)\n",
        "tri.fit(x_train_t1,y_train_t)\n",
        "y_pred = tri.predict(x_test_t1)\n",
        "acc = accuracy_score(y_test_t, y_pred)\n",
        "print(acc)\n",
        "f1 = f1_score(y_test_t,y_pred)\n",
        "print(f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LinearModels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
